import sys
from llama_cpp import Llama

# Load the SQLCoder model
llm = Llama(
    model_path="./sqlcoder-7b-2-GGUF.Q4_K_M.gguf",  # Update with the correct path
    n_ctx=8192,   # Context length (increase if needed)
    n_threads=8,  # Adjust based on your CPU cores
    n_gpu_layers=35  # Offload layers to GPU (adjust if needed)
)

# Define the database schema
schema = """
CREATE TABLE employees (
    id INT PRIMARY KEY,
    name VARCHAR(100),
    department VARCHAR(50),
    salary INT,
    hire_date DATE
);

CREATE TABLE departments (
    id INT PRIMARY KEY,
    name VARCHAR(50),
    manager_id INT,
    FOREIGN KEY (manager_id) REFERENCES employees(id)
);
"""

# Get user input for the question
question = input("Enter your natural language question: ")

# Format the prompt
prompt = f"""
### Schema: 
{schema}

### Question:
{question}

### SQL Query:
"""

# Run inference
output = llm(prompt, max_tokens=256, stop=["\n"])

# Print the generated SQL query
print("\nGenerated SQL Query:\n", output["choices"][0]["text"])
