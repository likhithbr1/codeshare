
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

# Model Name (TinyLlama)
MODEL_NAME = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"

# Load Model and Tokenizer
def load_model():
    print("‚è≥ Loading TinyLlama model... This may take a minute.")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_NAME,
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,  # Handle CPU/GPU
        device_map="auto", 
    )
    print("‚úÖ Model loaded successfully!")
    return tokenizer, model

# Generate SQL Query
def generate_sql(question, schema, tokenizer, model, max_tokens=128):
    input_text = (
        "You are an expert SQL query generator.\n"
        "Generate a syntactically correct SQL query based on the given schema and question.\n\n"
        f"### Schema:\n{schema}\n\n"
        f"### Question:\n{question}\n\n"
        "### Response:\n"
        "SQL QUERY:\n"
    )

    pipe = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        max_new_tokens=max_tokens,
        do_sample=True,   # Enable sampling for better SQL generation
        temperature=0.3,   # Adjusted for balanced accuracy
        top_p=0.9,       
        return_full_text=False,
    )

    generated_text = pipe(input_text, num_return_sequences=1)[0]["generated_text"]

    # Post-process output to ensure valid SQL query
    sql_query = generated_text.strip().split("\n")[0]  # Take only the first line
    if not sql_query.upper().startswith(("SELECT", "INSERT", "UPDATE", "DELETE", "CREATE", "DROP")):
        return "ERROR: Model failed to generate a valid SQL query."
    
    return sql_query

def main():
    # Load model once
    tokenizer, model = load_model()

    # Load schema from file
    schema_file = 'schema.txt'
    try:
        with open(schema_file, 'r') as f:
            schema = f.read().strip()
        print("‚úÖ Schema loaded.")
    except FileNotFoundError:
        print(f"‚ùå Error: {schema_file} not found.")
        return

    print("\nüîπ Text-to-SQL Generator is ready! Type your question below.")
    print("üõë Type 'exit' to quit the application.\n")

    while True:
        question = input("üí¨ Enter your natural language question: ")
        if question.lower() in ["exit", "quit"]:
            print("üëã Exiting application. Goodbye!")
            break

        print("\n‚è≥ Generating SQL Query...\n")
        sql_query = generate_sql(question, schema, tokenizer, model)
        print(f"‚úÖ Generated SQL Query:\n{sql_query}\n")

if __name__ == "__main__":
    main()
